{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# int(glob.glob('./datasets/images/*')[0].split('/')[-1].split('.')[0].split('_')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=84x84 at 0x7F1AD235D280>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = Image.open(glob.glob('./datasets/images/*')[0])\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(64),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.CenterCrop(64),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean, std)\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "\n",
    "class span75speaker(Dataset):\n",
    "    def __init__(self, image_path = './datasets/images', audio_path = './datasets/audios', transform=None, target_transform=None):\n",
    "        self.images = glob.glob(f'{image_path}/*')  # Could be a list: ['./train/input/image_1.bmp', './train/input/image_2.bmp', ...]\n",
    "        # self.audios = glob.glob(f'{audio_path}/*')  # Could be a nested list: [['./train/GT/image_1_1.bmp', './train/GT/image_1_2.bmp', ...], ['./train/GT/image_2_1.bmp', './train/GT/image_2_2.bmp', ...]]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.images[index].split('/')[-1].split('.')[0].split('-')\n",
    "        img = Image.open(self.images[index])\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        aud_embs = torch.load(f'./datasets/audios/{image_name[0]}.pt')\n",
    "        aud_emb = aud_embs[:,min(int(image_name[-1]), aud_embs.size(1) - 1),:]\n",
    "\n",
    "        return (img, aud_emb)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14162/1612145688.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraindata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspan75speaker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maud\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_14162/917398573.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0maud_embs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./datasets/audios/{image_name[0]}.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0maud_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maud_embs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maud_embs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "traindata = span75speaker(transform = data_transforms['val'])\n",
    "(img, aud) = next(iter(traindata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fbf9af61b20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['last_hidden_state', 'extract_features'])\n",
      "torch.Size([1, 1413, 1024])\n",
      "torch.Size([1, 1413, 512])\n"
     ]
    }
   ],
   "source": [
    "# import librosa\n",
    "# import torch\n",
    "# from transformers import Wav2Vec2FeatureExtractor, Wav2Vec2Model\n",
    "\n",
    "input_audio, sample_rate = librosa.load(\"/mnt/c/Users/PCM/Dropbox/span/sub006/2drt/audio/sub006_2drt_01_vcv1_r1_video.wav\",  sr=16000)\n",
    "\n",
    "model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "model = Wav2Vec2Model.from_pretrained(model_name)\n",
    "\n",
    "i= feature_extractor(input_audio, return_tensors=\"pt\", sampling_rate=sample_rate)\n",
    "with torch.no_grad():\n",
    "  o= model(i.input_values)\n",
    "\n",
    "print(o.keys())\n",
    "print(o.last_hidden_state.shape)\n",
    "print(o.extract_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1413"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.last_hidden_state.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sub006_2drt_01_vcv1_r1_video'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aud_list = glob.glob(f'/mnt/c/Users/PCM/Dropbox/span/sub006/2drt/audio/*')[0]\n",
    "# aud_list.split('/')[-1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_audio_emds(in_path = '/mnt/c/Users/PCM/Dropbox/span/sub006/2drt/audio', out_path = './datasets/audios'):\n",
    "    aud_list = glob.glob(f'{in_path}/*')\n",
    "    for path in aud_list:\n",
    "        name = path.split('/')[-1].split('.')[0]\n",
    "        input_audio, sample_rate = librosa.load(f\"{in_path}/{name}.wav\",  sr=16000)\n",
    "\n",
    "        model_name = \"facebook/wav2vec2-large-xlsr-53\"\n",
    "        feature_extractor = Wav2Vec2FeatureExtractor.from_pretrained(model_name)\n",
    "        model = Wav2Vec2Model.from_pretrained(model_name)\n",
    "\n",
    "        i= feature_extractor(input_audio, return_tensors=\"pt\", sampling_rate=sample_rate)\n",
    "        with torch.no_grad():\n",
    "            o = model(i.input_values)\n",
    "        torch.save(o.last_hidden_state, f'{out_path}/{name}.pt')\n",
    "\n",
    "# create_audio_emds(in_path = '/mnt/c/Users/PCM/Dropbox/span/sub006/2drt/audio', out_path = './datasets/audios/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1685, 1024])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa = torch.load('/mnt/c/Users/PCM/Documents/GitHub/SPAN-rtmri/datasets/audios/sub001_2drt_01_vcv1_r2_video.pt')\n",
    "aaa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = glob.glob('/mnt/c/Users/PCM/Dropbox/span/sub*')\n",
    "for sub in subjects:\n",
    "    create_audio_emds(in_path = f'{sub}/2drt/audio', out_path = './datasets/audios')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import subprocess\n",
    "\n",
    "subjects = glob.glob('/mnt/c/Users/PCM/Dropbox/span/sub*')\n",
    "for sub in subjects:\n",
    "    vids = glob.glob(f'{sub}/2drt/video/*')\n",
    "    # audio_foler = f'{sub}/2drt/audio'\n",
    "    # subprocess.call(f'mkdir {audio_foler}', shell=True)\n",
    "    for i in range(len(vids)):\n",
    "        command = f\"ffmpeg -i {vids[i]} -r 50 ./datasets/images/{vids[i].split('/')[-1].split('.')[0]}-%d.png\"\n",
    "        subprocess.call(command, shell=True)\n",
    "        # !ffmpeg -i vids[i] -r 50 f'./datasets/images/{vids[i].split('/')[-1].split('.')[0]}-%d.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample video to frames in 50 fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i '/mnt/c/Users/PCM/Dropbox/span/sub006/2drt/video/sub006_2drt_01_vcv1_r1_video.mp4' -r 50 './datasets/images/sub006_2drt_01_vcv1_r1_video-%d.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from imagen_pytorch import Unet, Imagen\n",
    "from imagen_pytorch import Unet, Imagen, ImagenTrainer\n",
    "# from imagen_pytorch.data import Dataset\n",
    "# unet for imagen\n",
    "\n",
    "unet1 = Unet(\n",
    "    dim = 32,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True, True),\n",
    "    layer_cross_attns = (False, True, True, True)\n",
    ")\n",
    "\n",
    "unet2 = Unet(\n",
    "    dim = 32,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = (2, 4, 8, 8),\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = (False, False, False, True)\n",
    ")\n",
    "\n",
    "# imagen, which contains the unets above (base unet and super resoluting ones)\n",
    "\n",
    "imagen = Imagen(\n",
    "    text_embed_dim=1024,\n",
    "    unets = (unet1, unet2),\n",
    "    image_sizes = (64, 64),\n",
    "    timesteps = 1000,\n",
    "    cond_drop_prob = 0.1\n",
    ").cuda()\n",
    "\n",
    "# mock images (get a lot of this) and text encodings from large T5\n",
    "\n",
    "# text_embeds = o.extract_features.view(1413,1,512)[:10].cuda #torch.randn(1, 1, 512).cuda()\n",
    "# images = torch.randn(1, 3, 64, 64).cuda()\n",
    "\n",
    "dataset = span75speaker(transform = data_transforms['val'])\n",
    "\n",
    "trainer = ImagenTrainer(\n",
    "    imagen = imagen,\n",
    "    split_valid_from_train = True # whether to split the validation dataset from the training\n",
    ").cuda()\n",
    "trainer.add_train_dataset(dataset, batch_size = 32)\n",
    "\n",
    "for i in range(1,200000):\n",
    "    loss = trainer.train_step(unet_number = 1, max_batch_size = 32)\n",
    "    print(f'loss: {loss}')\n",
    "\n",
    "    if not (i % 50):\n",
    "        valid_loss = trainer.valid_step(unet_number = 1, max_batch_size = 32)\n",
    "        print(f'valid loss: {valid_loss}')\n",
    "\n",
    "    if not (i % 100) and trainer.is_main: # is_main makes sure this can run in distributed\n",
    "        images = trainer.sample(text_embeds = aud.unsqueeze(0), batch_size = 1, return_pil_images = True, stop_at_unet_number=1) # returns List[Image]\n",
    "        images[0].save(f'./sample_log/sample-{i // 100}.png')\n",
    "\n",
    "# feed images into imagen, training each unet in the cascade\n",
    "\n",
    "# for i in (1, 2):\n",
    "#     loss = imagen(images, text_embeds = text_embeds, unet_number = i)\n",
    "#     loss.backward()\n",
    "\n",
    "# do the above for many many many many steps\n",
    "# now you can sample an image based on the text embeddings from the cascading ddpm\n",
    "\n",
    "# images = imagen.sample(texts = [\n",
    "#     'a whale breaching from afar',\n",
    "#     'young girl blowing out candles on her birthday cake',\n",
    "#     'fireworks with blue and green sparkles'\n",
    "# ], cond_scale = 3.)\n",
    "\n",
    "# images.shape # (3, 3, 256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(imagen.state_dict(), './imagen-span-070823')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imagen(\n",
       "  (noise_schedulers): ModuleList(\n",
       "    (0): GaussianDiffusionContinuousTimes()\n",
       "    (1): GaussianDiffusionContinuousTimes()\n",
       "  )\n",
       "  (lowres_noise_schedule): GaussianDiffusionContinuousTimes()\n",
       "  (unets): ModuleList(\n",
       "    (0): Unet(\n",
       "      (init_conv): CrossEmbedLayer(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (2): Conv2d(3, 8, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7))\n",
       "        )\n",
       "      )\n",
       "      (to_time_hiddens): Sequential(\n",
       "        (0): LearnedSinusoidalPosEmb()\n",
       "        (1): Linear(in_features=17, out_features=128, bias=True)\n",
       "        (2): SiLU()\n",
       "      )\n",
       "      (to_time_cond): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (to_time_tokens): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=1024, bias=True)\n",
       "        (1): Rearrange('b (r d) -> b r d', r=2)\n",
       "      )\n",
       "      (norm_cond): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (text_to_cond): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (attn_pool): PerceiverResampler(\n",
       "        (pos_emb): Embedding(512, 512)\n",
       "        (to_latents_from_mean_pooled_seq): Sequential(\n",
       "          (0): LayerNorm()\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): Rearrange('b (n d) -> b n d', n=4)\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PerceiverAttention(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_latents): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): LayerNorm()\n",
       "              (1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): LayerNorm()\n",
       "              (4): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): PerceiverAttention(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_latents): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): LayerNorm()\n",
       "              (1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): LayerNorm()\n",
       "              (4): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (to_text_non_attn_cond): Sequential(\n",
       "        (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "        (2): SiLU()\n",
       "        (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): None\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Identity()\n",
       "          (4): Sequential(\n",
       "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): None\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (cross_attn): CrossAttention(\n",
       "              (norm): LayerNorm()\n",
       "              (norm_context): Identity()\n",
       "              (to_q): Linear(in_features=32, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=32, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=32, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=32, out_features=128, bias=False)\n",
       "                  (to_context): Sequential(\n",
       "                    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=32, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): LayerNorm()\n",
       "                  (1): Linear(in_features=32, out_features=64, bias=False)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): LayerNorm()\n",
       "                  (4): Linear(in_features=64, out_features=32, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
       "            (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): None\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (cross_attn): CrossAttention(\n",
       "              (norm): LayerNorm()\n",
       "              (norm_context): Identity()\n",
       "              (to_q): Linear(in_features=64, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=64, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=64, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
       "                  (to_context): Sequential(\n",
       "                    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=64, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): LayerNorm()\n",
       "                  (1): Linear(in_features=64, out_features=128, bias=False)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): LayerNorm()\n",
       "                  (4): Linear(in_features=128, out_features=64, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Sequential(\n",
       "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
       "            (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): None\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (cross_attn): CrossAttention(\n",
       "              (norm): LayerNorm()\n",
       "              (norm_context): Identity()\n",
       "              (to_q): Linear(in_features=128, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=128, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=128, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=128, out_features=128, bias=False)\n",
       "                  (to_context): Sequential(\n",
       "                    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=128, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): LayerNorm()\n",
       "                  (1): Linear(in_features=128, out_features=256, bias=False)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): LayerNorm()\n",
       "                  (4): Linear(in_features=256, out_features=128, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Parallel(\n",
       "            (fns): ModuleList(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "            (cross_attn): CrossAttention(\n",
       "              (norm): LayerNorm()\n",
       "              (norm_context): Identity()\n",
       "              (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=256, out_features=128, bias=False)\n",
       "                  (to_context): Sequential(\n",
       "                    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): LayerNorm()\n",
       "                  (1): Linear(in_features=256, out_features=512, bias=False)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): LayerNorm()\n",
       "                  (4): Linear(in_features=512, out_features=256, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "            )\n",
       "            (cross_attn): CrossAttention(\n",
       "              (norm): LayerNorm()\n",
       "              (norm_context): Identity()\n",
       "              (to_q): Linear(in_features=128, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=128, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=128, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=128, out_features=128, bias=False)\n",
       "                  (to_context): Sequential(\n",
       "                    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=128, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): LayerNorm()\n",
       "                  (1): Linear(in_features=128, out_features=256, bias=False)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): LayerNorm()\n",
       "                  (4): Linear(in_features=256, out_features=128, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "            )\n",
       "            (cross_attn): CrossAttention(\n",
       "              (norm): LayerNorm()\n",
       "              (norm_context): Identity()\n",
       "              (to_q): Linear(in_features=64, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=64, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=64, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=64, out_features=128, bias=False)\n",
       "                  (to_context): Sequential(\n",
       "                    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=64, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): LayerNorm()\n",
       "                  (1): Linear(in_features=64, out_features=128, bias=False)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): LayerNorm()\n",
       "                  (4): Linear(in_features=128, out_features=64, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attn): CrossAttention(\n",
       "          (norm): LayerNorm()\n",
       "          (norm_context): Identity()\n",
       "          (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (1): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): TransformerBlock(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=256, out_features=128, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): LayerNorm()\n",
       "              (1): Linear(in_features=256, out_features=512, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): LayerNorm()\n",
       "              (4): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attn): CrossAttention(\n",
       "          (norm): LayerNorm()\n",
       "          (norm_context): Identity()\n",
       "          (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (1): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (upsample_combiner): UpsampleCombiner()\n",
       "      (final_res_block): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (gca): GlobalContext(\n",
       "          (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (final_conv): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (1): Unet(\n",
       "      (init_conv): CrossEmbedLayer(\n",
       "        (convs): ModuleList(\n",
       "          (0): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): Conv2d(6, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "          (2): Conv2d(6, 8, kernel_size=(15, 15), stride=(1, 1), padding=(7, 7))\n",
       "        )\n",
       "      )\n",
       "      (to_time_hiddens): Sequential(\n",
       "        (0): LearnedSinusoidalPosEmb()\n",
       "        (1): Linear(in_features=17, out_features=256, bias=True)\n",
       "        (2): SiLU()\n",
       "      )\n",
       "      (to_time_cond): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (to_time_tokens): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): Rearrange('b (r d) -> b r d', r=2)\n",
       "      )\n",
       "      (to_lowres_time_hiddens): Sequential(\n",
       "        (0): LearnedSinusoidalPosEmb()\n",
       "        (1): Linear(in_features=17, out_features=256, bias=True)\n",
       "        (2): SiLU()\n",
       "      )\n",
       "      (to_lowres_time_cond): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (to_lowres_time_tokens): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "        (1): Rearrange('b (r d) -> b r d', r=2)\n",
       "      )\n",
       "      (norm_cond): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (text_to_cond): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (attn_pool): PerceiverResampler(\n",
       "        (pos_emb): Embedding(512, 512)\n",
       "        (to_latents_from_mean_pooled_seq): Sequential(\n",
       "          (0): LayerNorm()\n",
       "          (1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (2): Rearrange('b (n d) -> b n d', n=4)\n",
       "        )\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): PerceiverAttention(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_latents): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): LayerNorm()\n",
       "              (1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): LayerNorm()\n",
       "              (4): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): PerceiverAttention(\n",
       "              (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm_latents): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              (to_q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=512, bias=False)\n",
       "                (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): LayerNorm()\n",
       "              (1): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): LayerNorm()\n",
       "              (4): Linear(in_features=2048, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (to_text_non_attn_cond): Sequential(\n",
       "        (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (2): SiLU()\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (downs): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): None\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Identity()\n",
       "          (4): Sequential(\n",
       "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
       "            (1): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): None\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (3): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Identity()\n",
       "          (4): Sequential(\n",
       "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
       "            (1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): None\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (3): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (4): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (5): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (6): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (7): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): Identity()\n",
       "          (4): Sequential(\n",
       "            (0): Rearrange('b c (h s1) (w s2) -> b (c s1 s2) h w', s1=2, s2=2)\n",
       "            (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): None\n",
       "          (1): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (cross_attn): CrossAttention(\n",
       "              (norm): LayerNorm()\n",
       "              (norm_context): Identity()\n",
       "              (to_q): Linear(in_features=128, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=128, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Identity()\n",
       "          )\n",
       "          (2): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (3): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (4): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (5): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (6): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "            (7): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Identity()\n",
       "            )\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=128, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=128, out_features=128, bias=False)\n",
       "                  (to_context): Sequential(\n",
       "                    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=128, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): LayerNorm()\n",
       "                  (1): Linear(in_features=128, out_features=256, bias=False)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): LayerNorm()\n",
       "                  (4): Linear(in_features=256, out_features=128, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (4): Parallel(\n",
       "            (fns): ModuleList(\n",
       "              (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              (1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ups): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "            )\n",
       "            (cross_attn): CrossAttention(\n",
       "              (norm): LayerNorm()\n",
       "              (norm_context): Identity()\n",
       "              (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (3): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (4): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (5): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (6): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (7): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (layers): ModuleList(\n",
       "              (0): ModuleList(\n",
       "                (0): Attention(\n",
       "                  (norm): LayerNorm()\n",
       "                  (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "                  (to_kv): Linear(in_features=256, out_features=128, bias=False)\n",
       "                  (to_context): Sequential(\n",
       "                    (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                    (1): Linear(in_features=512, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (to_out): Sequential(\n",
       "                    (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "                    (1): LayerNorm()\n",
       "                  )\n",
       "                )\n",
       "                (1): Sequential(\n",
       "                  (0): LayerNorm()\n",
       "                  (1): Linear(in_features=256, out_features=512, bias=False)\n",
       "                  (2): GELU(approximate='none')\n",
       "                  (3): LayerNorm()\n",
       "                  (4): Linear(in_features=512, out_features=256, bias=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (3): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (4): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (5): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (6): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (7): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (2): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (3): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(96, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): PixelShuffleUpsample(\n",
       "            (net): Sequential(\n",
       "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): SiLU()\n",
       "              (2): PixelShuffle(upscale_factor=2)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): ResnetBlock(\n",
       "            (time_mlp): Sequential(\n",
       "              (0): SiLU()\n",
       "              (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "            )\n",
       "            (block1): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (block2): Block(\n",
       "              (norm): ChanRMSNorm()\n",
       "              (activation): SiLU()\n",
       "              (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            )\n",
       "            (res_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): ModuleList(\n",
       "            (0): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "            (1): ResnetBlock(\n",
       "              (time_mlp): Sequential(\n",
       "                (0): SiLU()\n",
       "                (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "              )\n",
       "              (block1): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (block2): Block(\n",
       "                (norm): ChanRMSNorm()\n",
       "                (activation): SiLU()\n",
       "                (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "              )\n",
       "              (gca): GlobalContext(\n",
       "                (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "                (net): Sequential(\n",
       "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (1): SiLU()\n",
       "                  (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "                  (3): Sigmoid()\n",
       "                )\n",
       "              )\n",
       "              (res_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            )\n",
       "          )\n",
       "          (2): Identity()\n",
       "          (3): Identity()\n",
       "        )\n",
       "      )\n",
       "      (mid_block1): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attn): CrossAttention(\n",
       "          (norm): LayerNorm()\n",
       "          (norm_context): Identity()\n",
       "          (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (1): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (mid_attn): TransformerBlock(\n",
       "        (layers): ModuleList(\n",
       "          (0): ModuleList(\n",
       "            (0): Attention(\n",
       "              (norm): LayerNorm()\n",
       "              (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "              (to_kv): Linear(in_features=256, out_features=128, bias=False)\n",
       "              (to_out): Sequential(\n",
       "                (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "                (1): LayerNorm()\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): LayerNorm()\n",
       "              (1): Linear(in_features=256, out_features=512, bias=False)\n",
       "              (2): GELU(approximate='none')\n",
       "              (3): LayerNorm()\n",
       "              (4): Linear(in_features=512, out_features=256, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mid_block2): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        )\n",
       "        (cross_attn): CrossAttention(\n",
       "          (norm): LayerNorm()\n",
       "          (norm_context): Identity()\n",
       "          (to_q): Linear(in_features=256, out_features=512, bias=False)\n",
       "          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n",
       "          (to_out): Sequential(\n",
       "            (0): Linear(in_features=512, out_features=256, bias=False)\n",
       "            (1): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (upsample_combiner): UpsampleCombiner()\n",
       "      (final_res_block): ResnetBlock(\n",
       "        (time_mlp): Sequential(\n",
       "          (0): SiLU()\n",
       "          (1): Linear(in_features=256, out_features=64, bias=True)\n",
       "        )\n",
       "        (block1): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (block2): Block(\n",
       "          (norm): ChanRMSNorm()\n",
       "          (activation): SiLU()\n",
       "          (project): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (gca): GlobalContext(\n",
       "          (to_k): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (net): Sequential(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (1): SiLU()\n",
       "            (2): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (3): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (res_conv): Identity()\n",
       "      )\n",
       "      (final_conv): Conv2d(35, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet1 = Unet(\n",
    "    dim = 32,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = 3,\n",
    "    layer_attns = (False, True, True, True),\n",
    "    layer_cross_attns = (False, True, True, True)\n",
    ")\n",
    "\n",
    "unet2 = Unet(\n",
    "    dim = 32,\n",
    "    cond_dim = 512,\n",
    "    dim_mults = (1, 2, 4, 8),\n",
    "    num_resnet_blocks = (2, 4, 8, 8),\n",
    "    layer_attns = (False, False, False, True),\n",
    "    layer_cross_attns = (False, False, False, True)\n",
    ")\n",
    "\n",
    "# imagen, which contains the unets above (base unet and super resoluting ones)\n",
    "\n",
    "imagen = Imagen(\n",
    "    text_embed_dim=1024,\n",
    "    unets = (unet1, unet2),\n",
    "    image_sizes = (64, 64),\n",
    "    timesteps = 1000,\n",
    "    cond_drop_prob = 0.1\n",
    ").cuda()\n",
    "\n",
    "imagen.load_state_dict(torch.load('./imagen-span-070823'))\n",
    "imagen.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002466440200805664,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": null,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551c58ba7afb452ab0d7e219d63cd265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002531290054321289,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "sampling loop time step",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a67248f5dd408589a6904b38b2e87b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.002212047576904297,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "sampling loop time step",
       "rate": null,
       "total": 1000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb11114c15e40fda825bbfdf3e43387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sampling loop time step:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 64, 64])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "images = imagen.sample(text_embeds = torch.randn(1, 1, 512).cuda(), cond_scale = 3.)\n",
    "\n",
    "images.shape # (3, 3, 256, 256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
